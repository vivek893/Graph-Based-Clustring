# -*- coding: utf-8 -*-
"""Graph based clustring and K-mean clustring.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1afULhXU8n-eI43VD0dPR4uqJOlfb2geU

# Importing the Python libraries
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report

import warnings
warnings.filterwarnings('ignore')

"""Importing the dataset"""

train_data=pd.read_csv('titanic_survival.csv',encoding='utf8')
data=train_data.copy()

"""# Pandas Dataframes"""

data.head() # show first five row of dataframe

# show last five row of dataframe
data.tail()

"""By default, the first row of the csv file has been used as column names. We will soon see how to fix that."""

data.columns

"""To see the datatypes of each column we do the following:"""

data.dtypes

print("Titanic Data Size  :" ,data.size)
print("Titanic Data Shape :" ,data.shape)

"""We may get a quick analysis of our data using describe()
Statistical details of Dataframe
"""

data.describe()

"""# Visualization of Data"""

# outlier in age columns.
plt.subplot(2,2,1)
sns.boxplot(x=data['Age'],color="deeppink",showfliers=True)
plt.subplot(2,2,2)
sns.boxplot(x=data['Fare'],color="Blue",showfliers=True)
plt.show

"""Visualization of fare Column without Outliers

Draw a graph and compare which one is more skew()
"""

# comapre between the Age and Fare
plt.figure(figsize=(12,6))
#plt.subplot(2, 2, 1)
sns.displot(data['Age'],bins=15,color="blue")
#plt.subplot(2,2,2)
sns.displot(data['Embarked'])

plt.show()

plt.figure(figsize=(12,6))

plt.subplot(2,2,1)
sns.distplot(data['Age'],bins=15,color="deepPink")
plt.subplot(2,2,2)
sns.boxplot(x=data['Age'],color="deeppink")

plt.subplot(2,2,3)
sns.distplot(data['Fare'],bins=10,color="Blue")
plt.subplot(2,2,4)
sns.boxplot(x=data['Fare'],color="orange")

plt.show()

plt.figure(figsize=(12,6))

bound= plt.subplot(1,2,1)
# it count how many male and how many females were present in titanic.
bound = sns.countplot(x='Sex', data=data)
bound.bar_label(bound.containers[0])   # bar graph
plt.title("Sex", fontsize=20)
bound1 =plt.subplot(1,2,2)
bound1=data['Sex'].value_counts().plot.pie(explode=[0.1, 0.1],autopct='%1.2f%%',shadow=True);  # pie graph
bound1.set_title(label = "Sex", fontsize = 20,color='Red',font='Lucida Calligraphy');

sns.countplot(x='Survived',data=data)

data['Survived'].value_counts()

"""other way to visualise data: FaceGrid
FaceGrid of Age
"""

g = sns.FacetGrid(data, col="Pclass")  # it basically make a class
g = g.map(plt.hist, "Age")

"""FaceGrid of Embarked : x-label is Age and y-label is Fare"""

Embark = sns.FacetGrid(data, col="Pclass", hue="Embarked")
Embark.map_dataframe(sns.scatterplot, x="Age", y="Fare")
Embark.add_legend()

plt.show()

"""FaceGrid of Sex. x-label is Age and y-label=Density"""

sns.FacetGrid(data, hue='Sex', height=3).map(sns.distplot, 'Age').add_legend()
plt.show()

# Another way to visualize the data is to use FacetGrid to plot multiple kedplots on one plot

figure = sns.FacetGrid(data, hue="Survived", aspect=4)
figure.map(sns.kdeplot, 'Age', shade=True)
oldest = data['Age'].max()
figure.set(xlim=(0, oldest))
figure.add_legend()
plt.show()

"""Joint of two plot: joint of Age and fare with Survive Graph"""

sns.jointplot(x="Age",y="Fare",data=data,color="olive",hue="Survived")
plt.show()

# visualization of outlier in Embarked column with respect to fare
plt.figure(figsize=(12,6))

plt.subplot(2,2,1)
sns.boxplot(y=data['Fare'],x=data['Embarked'],showfliers=True)
plt.subplot(2,2,2)
sns.barplot(y="Fare",x="Embarked",data=data)
plt.show()

corr=data.corr()#["Survived"]
plt.figure(figsize=(14, 10))
sns.heatmap(corr, vmax=.8, linewidths=0.01, square=True,annot=True,cmap='YlGnBu',linecolor="blue")
plt.title('Correlation between features')
plt.show()

# correlation heatmap of higly correlated features with SalePrice

corr = data.corr()
corr_features = corr.index[abs(corr["Fare"]) >= 0.25]
print(corr_features)

plt.figure(figsize=(10,8))
x_label= sns.heatmap(data[corr_features].corr(), cmap = "coolwarm", annot=True, linewidth=3)
# to fix the bug "first and last row cut in half of heatmap plot"
bottom, top = x_label.get_ylim()
x_label.set_ylim(bottom + 0.5, top - 0.5)
plt.show()

corr = data.corr()
mask = np.triu(np.ones_like(corr,dtype = bool))

plt.figure(dpi=100)
plt.title('Correlation Analysis')
sns.heatmap(corr,mask=mask,annot=True,lw=0,linecolor='white',cmap='viridis',fmt = "0.2f")
plt.xticks(rotation=40)
plt.yticks(rotation = 10)
plt.show()

"""# Data Preprocessing

# Visualizing the missing data before cleaning data (before removing null value)
"""

sns.heatmap(data.isnull(), yticklabels=False)

"""Counting the No of missing values in each column"""

data.isnull().sum().sort_values(ascending=False)

"""Calculating the percentage of missing values in Dataframe"""

per_mis_data=(data.isnull().sum())/(len(data))
print(per_mis_data)

def missing(data):
    missing_number=data.isnull().sum().sort_values(ascending=False)
    missing_percentage=(data.isnull().sum())/(len(data))
    missing_values=pd.concat([missing_number,missing_percentage],axis=1,keys=['missing_number','missing_percentage'])
    return missing_values

missing(data)

"""Removing the null value from the titanic data set"""

data["Cabin"].value_counts()

data.Cabin.mode()

# Filled the missing value in Age column with the mean value
data.Age.fillna(data.Age.mean(),inplace=True)
# Filled the missing value in Fare columns with mean Value
data.Fare.fillna(data.Fare.mean(),inplace=True)
# Filled the missing value in Cabin columns with mode Value
data.Cabin.fillna(data.Cabin.mode()[0],inplace=True)
data

"""Now check Data has cleaned or not"""

def missing(data):
    missing_number=data.isnull().sum().sort_values(ascending=False)
    missing_percentage=(data.isnull().sum())/(len(data))
    missing_values=pd.concat([missing_number,missing_percentage],axis=1,keys=['missing_number','missing_percentage'])
    return missing_values

missing(data)  # now my data is cleaned

sns.heatmap(data.isnull(), yticklabels=False)

# now check shape and size of data
print("Shape of titanic data is:",data.shape)
print("size of the titanic data is:",data.size)

data.describe()

"""# Remove outlier from Age, fare, Embarked column

find 25% value and 75%value and match with statical data
"""

percent_25_age=data["Age"].quantile(0.25)   # verify 25% is 23.0
percent_75_age=data["Age"].quantile(0.75)   # verify 75% is 35.75
print("25% of age:",percent_25_age,"75% of age:",percent_75_age)
percent_25_fare=data["Fare"].quantile(0.25)   # verify 25% is7.8958
percent_75_fare=data["Fare"].quantile(0.75)   # verify 75% is 31.5
print("25% of fare:",percent_25_fare,"75% of fare:",percent_75_fare)

"""find IQR(Range)=maximum(Q3)-minimum(Q1)"""

IQR_age=percent_75_age-percent_25_age
IQR_fare=percent_75_fare-percent_25_fare
print("IQR of age:",IQR_age)
print("IQR of Fare:",IQR_fare)

"""find lowerlimit(minimum value ) upperlimit(Maximum value)"""

lower_limit_age=percent_25_age-1.5*IQR_age
upper_limit_age=percent_75_age+1.5* IQR_age
lower_limit_fare=percent_25_fare-1.5*IQR_fare
upper_limit_fare=percent_75_fare+1.5*IQR_fare
print("lower limit of age:",lower_limit_age,"upper limit of age:",upper_limit_age)
print("lower limit of fare:",lower_limit_fare,"upper limit of fare:",upper_limit_fare)

"""outlier data"""

# outlier data of age
outlier_data_age=data[(data.Age<lower_limit_age)|(data.Age>upper_limit_age)]
outlier_data_age.head()

#outlier data of fare
outlier_data_fare=data[(data.Fare<lower_limit_fare)|(data.Fare>upper_limit_fare)]
outlier_data_fare.head()

# Reset the index
outlier_data_age.reset_index(drop = True, inplace = True)  ## Reset the indices
outlier_data_age.head()

outlier_data_fare.reset_index(drop = True, inplace = True)  ## Reset the indices
outlier_data_fare.head()

"""No outlier data. data within cluster"""

no_outlier_age=data[(data.Age>=lower_limit_age)&(data.Age<upper_limit_age)]
no_outlier_age.head()

no_outlier_fare=data[(data.Fare>=lower_limit_fare)&(data.Fare<upper_limit_fare)]
no_outlier_fare.head()

# capping: no_outlier find
new_df_cap=data
new_df_cap['Fare']=np.where(new_df_cap['Fare']>upper_limit_fare,
                           upper_limit_fare,
                           np.where(new_df_cap['Fare']<lower_limit_fare,
                                    lower_limit_fare,
                                    new_df_cap['Fare']
                                   )
                          )

plt.subplot(2,2,1)
sns.boxplot(x=outlier_data_age['Age'],color="Pink")
plt.subplot(2,2,2)
sns.boxplot(x=new_df_cap['Fare'],color="orange",showfliers=True)

"""Categorical value is converted into numerical value by using categorical_encode"""

pip install category_encoders

# Converting the categorical variable into the numerical variable by using category_encoder
import category_encoders as ce
encoder = ce.OrdinalEncoder(cols=['Survived','Pclass','Sex','Embarked'])
titanic_encoded = encoder.fit_transform(data)
titanic_encoded.head()

"""Splitting Independent and Dependent Variable"""

X = titanic_encoded.drop(['Survived'],axis=1)
y = data['Survived']

"""Splitting train and test set"""

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=.3,random_state= 21)
print("Shape of X_train data is:",X_train.shape,":::  Size of X_train data is:",X_train.size)
print("Shape of X_test data is:",X_test.shape," :::  Size of X_test data is:",X_test.size)
print("Shape of y_train data is:",y_train.shape,":::  Size of y_train data is:",y_train.size)
print("Shape of y_test data is:",y_test.shape," :::  Size of y_test data is:",X_test.size)

data.nunique()

data["Pclass"] = data["Pclass"].astype('category')
data["Sex"] = data["Sex"].astype('category')
data["Embarked"] = data["Embarked"].astype('category')
data["Survived"] = data["Survived"].astype('category')
X_train["Pclass"] = X_train["Pclass"].astype('category')

X_train.dtypes

#defining numerical columns in data:
numeric_columns=data.select_dtypes(['float64','int64']).columns
numeric_columns

cat_column=X_train.select_dtypes(['object','category']).columns
cat_column

import pandas as pd
data['Sex'] = data['Sex'].replace({'male': 1, 'female': 2})
data['Sex'] = data['Sex'].astype(int)

train_data=data.copy()

pip install --upgrade networkx

import pandas as pd
from sklearn.cluster import SpectralClustering
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics.pairwise import cosine_similarity

data=train_data
data = data[["Survived", "Sex"]]

# Handle missing values (if any)
data = data.dropna()

# Encode categorical features (Sex)
le = LabelEncoder()
data["Sex"] = le.fit_transform(data["Sex"])
data['Survived']=le.fit_transform(data['Survived'])

# Create a similarity matrix using cosine similarity
similarity_matrix = pd.DataFrame(cosine_similarity(data))

# Apply Spectral Clustering (adjust n_clusters based on your analysis)
clustering = SpectralClustering(n_clusters=2, affinity='precomputed')
labels = clustering.fit_predict(similarity_matrix)

# Print the cluster assignments
print("Cluster assignments:", labels)

import matplotlib.pyplot as plt
import seaborn as sns

# Add the cluster assignments to the original DataFrame
data['Cluster'] = labels

# Analyze cluster characteristics
cluster_summary = data.groupby('Cluster').mean()
print(cluster_summary)

# Visualize the clusters
sns.scatterplot(x='Survived', y='Sex', hue='Cluster', data=data, palette='viridis')
plt.title('Spectral Clustering Results')
plt.show()

import pandas as pd
from sklearn.cluster import SpectralClustering
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics.pairwise import cosine_similarity
import matplotlib.pyplot as plt
import seaborn as sns

# Assuming 'data' is your DataFrame
data=train_data
# Select the relevant columns
data = data[["Survived", "Sex"]]

# Encode categorical features (Sex)
le = LabelEncoder()
data["Sex"] = le.fit_transform(data["Sex"])
data["Survived"]=le.fit_transform(data["Survived"])

# Create a similarity matrix using cosine similarity
similarity_matrix = pd.DataFrame(cosine_similarity(data))

# Apply Spectral Clustering (adjust n_clusters based on your analysis)
clustering = SpectralClustering(n_clusters=2, affinity='precomputed')
labels = clustering.fit_predict(similarity_matrix)

# Add the cluster assignments to the original DataFrame
data['Cluster'] = labels

# Print the cluster assignments
print("Cluster assignments:", labels)

# Analyze cluster characteristics
cluster_summary = data.groupby('Cluster').mean()
print("Graph-based Cluster Characteristics:")
print(cluster_summary)

# Visualize the clusters
sns.scatterplot(x='Survived', y='Sex', hue='Cluster', data=data, palette='viridis')
plt.title('graph based Clustering Results')
plt.show()

import pandas as pd
import scipy.sparse as sp
from sklearn.cluster import SpectralClustering
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import kneighbors_graph
from scipy.sparse import csr_matrix
from scipy.sparse.csgraph import minimum_spanning_tree
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
data=train_data

data = data[["Survived", "Sex"]]

# Handle missing values (if any)
data = data.dropna()

# Encode categorical features (Sex)
le = LabelEncoder()
data["Sex"] = le.fit_transform(data["Sex"])
data["Survived"] = le.fit_transform(data["Survived"])

# Create a k-Nearest Neighbors graph
knn_graph = kneighbors_graph(data, n_neighbors=5, mode='distance', include_self=False)

# Convert to CSR matrix
knn_graph_csr = csr_matrix(knn_graph)

# Create a minimal spanning tree using Prim's algorithm
mst = minimum_spanning_tree(knn_graph_csr)

# Convert the sparse matrix to a NetworkX graph
G = nx.Graph(mst)

# Apply Spectral Clustering
clustering = SpectralClustering(n_clusters=2, affinity='precomputed')

adjacency_matrix = nx.adjacency_matrix(G)
adjacency_matrix_sparse = sp.csr_matrix(adjacency_matrix)
labels = clustering.fit_predict(adjacency_matrix_sparse)
# Add the cluster assignments to the original DataFrame
data['Cluster'] = labels

# Print the cluster assignments
print("Cluster assignments:", labels)

# Analyze cluster characteristics
cluster_summary = data.groupby('Cluster').mean()
print("Cluster Characteristics:")
print(cluster_summary)

# Visualize the clusters
pos = nx.spring_layout(G)
nx.draw_networkx_nodes(G, pos, node_size=30, node_color=labels, cmap=plt.cm.RdYlBu)
nx.draw_networkx_edges(G, pos, alpha=0.5)
plt.title('Graph-based Clustering Results with k-Nearest Neighbors Graph')
plt.show()

from sklearn.metrics import silhouette_score

# Calculate silhouette score
silhouette_avg = silhouette_score(adjacency_matrix_sparse, labels)
print(f"Silhouette Score: {silhouette_avg}")

from sklearn.metrics import confusion_matrix

# Fit the LabelEncoder on all unique labels in 'Survived' column
le.fit(data['Survived'])

# Transform 'Survived' column
ground_truth_labels = le.transform(data['Survived'])

# Create confusion matrix
conf_matrix = confusion_matrix(ground_truth_labels, labels)
print("Confusion Matrix:")
print(conf_matrix)

plt.figure(figsize=(10, 6))

# Visualize the ground truth labels
sns.scatterplot(x='Survived', y='Sex', hue='Survived', data=data, palette='viridis', s=50)

# Visualize the predicted clusters
sns.scatterplot(x='Survived', y='Sex', hue='Cluster', data=data, palette='viridis', s=30, marker='s')

plt.title('Comparison of Ground Truth Labels and Predicted Clusters')
plt.show()

import pandas as pd
import scipy.sparse as sp
from sklearn.cluster import SpectralClustering
from sklearn.preprocessing import LabelEncoder
from sklearn.neighbors import kneighbors_graph
from scipy.sparse import csr_matrix
from scipy.sparse.csgraph import minimum_spanning_tree
import matplotlib.pyplot as plt
import seaborn as sns
import networkx as nx
data=train_data
# Assuming 'data' is your DataFrame
# Select the relevant columns
data = data[["Survived", "Sex","Age","Fare","Embarked"]]

# Encode categorical features (Sex)
le = LabelEncoder()
data["Sex"] = le.fit_transform(data["Sex"])
data["Embarked"] = le.fit_transform(data["Embarked"])

# Create a k-Nearest Neighbors graph
knn_graph = kneighbors_graph(data, n_neighbors=5, mode='distance', include_self=False)

# Convert to CSR matrix
knn_graph_csr = csr_matrix(knn_graph)

# Create a minimal spanning tree using Prim's algorithm
mst = minimum_spanning_tree(knn_graph_csr)

# Convert the sparse matrix to a NetworkX graph
G = nx.Graph(mst)

# Apply Spectral Clustering
clustering = SpectralClustering(n_clusters=2, affinity='precomputed')

adjacency_matrix = nx.adjacency_matrix(G)
adjacency_matrix_sparse = sp.csr_matrix(adjacency_matrix)
labels = clustering.fit_predict(adjacency_matrix_sparse)
# Add the cluster assignments to the original DataFrame
data['Cluster'] = labels

# Print the cluster assignments
print("Cluster assignments:", labels)

# Analyze cluster characteristics
cluster_summary = data.groupby('Cluster').mean()
print("Cluster Characteristics:")
print(cluster_summary)

# Visualize the clusters
pos = nx.spring_layout(G)
nx.draw_networkx_nodes(G, pos, node_size=30, node_color=labels, cmap=plt.cm.RdYlBu)
nx.draw_networkx_edges(G, pos, alpha=0.5)
plt.title('Graph-based Clustering Results with k-Nearest Neighbors Graph')
plt.show()

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
data=train_data
# Select the relevant columns
data = data[["Survived", "Sex"]]

# Encode categorical features (Sex)
le = LabelEncoder()
data["Sex"] = le.fit_transform(data["Sex"])
data["Survived"]=le.fit_transform(data["Survived"])

# Apply KMeans clustering (adjust n_clusters based on your analysis)
kmeans = KMeans(n_clusters=5, random_state=42)
data['Cluster_KMeans'] = kmeans.fit_predict(data)

# Print the cluster assignments
print("KMeans Cluster assignments:", data['Cluster_KMeans'].values)

# Analyze cluster characteristics
kmeans_cluster_summary = data.groupby('Cluster_KMeans').mean()
print("KMeans Cluster Characteristics:")
print(kmeans_cluster_summary)

# Visualize the KMeans clusters

plt.figure(figsize=(10, 6))

sns.scatterplot(x='Survived', y='Sex', hue='Cluster_KMeans', data=data, palette='viridis', s=50)
sns.scatterplot(x=kmeans.cluster_centers_[:, 0], y=kmeans.cluster_centers_[:, 1], s=50, color='red', marker='X', label='Centroid')

plt.title('KMeans Clustering Results')
plt.xlabel('Survived')
plt.ylabel('Sex')
plt.legend()
plt.show()

data.head()

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
import matplotlib.pyplot as plt
import seaborn as sns
data=train_data
data = data[["Survived", "Sex", "Age", "Fare", "Embarked"]]

# Handle missing values (if any)
data = data.dropna()

# Encode categorical features (Sex and Embarked)
le = LabelEncoder()
data["Sex"] = le.fit_transform(data["Sex"])
data["Embarked"] = le.fit_transform(data["Embarked"])

# Apply KMeans clustering (adjust n_clusters based on your analysis)
kmeans = KMeans(n_clusters=5, random_state=42)
data['Cluster_KMeans'] = kmeans.fit_predict(data)

# Print the cluster assignments
print("KMeans Cluster assignments:", data['Cluster_KMeans'].values)

# Analyze cluster characteristics
kmeans_cluster_summary = data.groupby('Cluster_KMeans').mean()
print("KMeans Cluster Characteristics:")
print(kmeans_cluster_summary)

# Visualize the KMeans clusters
plt.figure(figsize=(12, 8))

sns.scatterplot(x='Age', y='Fare', hue='Cluster_KMeans', data=data, palette='viridis', s=50)
sns.scatterplot(x=kmeans.cluster_centers_[:, 2], y=kmeans.cluster_centers_[:, 3], s=50, color='red', marker='X', label='Centroid')

plt.title('KMeans Clustering Results')
plt.xlabel('Age')
plt.ylabel('Fare')
plt.legend()
plt.show()

from sklearn.metrics import silhouette_score


print(data.columns)  # Check available columns

if 'Cluster' in data.columns:
    silhouette_avg = silhouette_score(data[['Survived', 'Sex']], data['Cluster'])
    print(f"Silhouette Score: {silhouette_avg}")
else:
    print("Column 'Cluster_KMeans' not found in the DataFrame.")

from sklearn.metrics import confusion_matrix
le.fit(data['Survived'])

ground_truth_labels = le.transform(data['Survived'])

# Create confusion matrix
conf_matrix = confusion_matrix(ground_truth_labels, data['Cluster_KMeans'])
print("Confusion Matrix:")
print(conf_matrix)

plt.figure(figsize=(10, 6))

# Visualize the ground truth labels
sns.scatterplot(x='Survived', y='Sex', hue='Survived', data=data, palette='viridis', s=50)

# Visualize the predicted clusters
sns.scatterplot(x='Survived', y='Sex', hue='Cluster_KMeans', data=data, palette='viridis', s=30, marker='s')

plt.title('Comparison of Ground Truth Labels and Predicted Clusters')
plt.show()